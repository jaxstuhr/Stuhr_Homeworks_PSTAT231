---
title: 'Homeowrk #5'
author: "Jaxon Stuhr"
date: "2022-11-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(here)
library(tidyverse)
library(janitor)
library(tidymodels)
library(glmnet)
```

## Elastic Net Tuning

Data Source: <https://www.kaggle.com/abcsds/pokemon>.

The [Pokémon](https://www.pokemon.com/us/) franchise encompasses video games, TV shows, movies, books, and a card game. This data set was drawn from the video game series and contains statistics about 721 Pokémon, or "pocket monsters." In Pokémon games, the user plays as a trainer who collects, trades, and battles Pokémon to (a) collect all the Pokémon and (b) become the champion Pokémon trainer.

Each Pokémon has a [primary type](https://bulbapedia.bulbagarden.net/wiki/Type) (some even have secondary types). Based on their type, a Pokémon is strong against some types, and vulnerable to others. (Think rock, paper, scissors.) A Fire-type Pokémon, for example, is vulnerable to Water-type Pokémon, but strong against Grass-type.

![Fig 1. Vulpix, a Fire-type fox Pokémon from Generation 1.](images/vulpix.png){width="196"}

The goal of this assignment is to build a statistical learning model that can predict the **primary type** of a Pokémon based on its generation, legendary status, and six battle statistics.

Read in the file and familiarize yourself with the variables using `pokemon_codebook.txt`.

```{r}
# read in pokemon data, set seed
pokemon_raw = read_csv(here("data", "Pokemon.csv"))
set.seed(1739)
```


### Exercise 1

```{r}
# clean names of pokemon data
pokemon_clean = pokemon_raw %>% 
  clean_names()
```

__clean_names()__ removed all capitals, spaces and characters other than letters, numbers, and "_" from the column names of pokemon_raw. These leaves a dataset with standardized parameter names that is much easier to work with. 

### Exercise 2

```{r}
# bar plot of type_1
ggplot(pokemon_clean, aes(x = type_1)) +
  geom_bar() + 
  labs(x = "Pokemon Type 1", y = "Count") +
  theme_minimal()
```

There are 18 classes of pokemon in the __type_1__ parameter, with all types having at least 15 observations other than "Flying". 


```{r}
# filter for only classes in: Bug, Fire, Grass, Normal, Water, or Psychic
pokemon = pokemon_clean %>% 
  filter(type_1 %in% c("Bug", "Fire", "Grass", "Normal", "Water", "Psychic")) %>% 
# convert type_1 and legendary to factors
  mutate(type_1 = factor(type_1)) %>% 
  mutate(legendary = factor(legendary, levels = c("TRUE", "FALSE"))) %>% 
  mutate(generation = factor(generation))
```

### Exercise 3

```{r}
# split pokemon data stratified by type_1
pokemon_split <- initial_split(pokemon, prop = 0.75,
                                strata = "type_1")
pokemon_train <- training(pokemon_split)
pokemon_test <- testing(pokemon_split)
# verify number of observations
dim(pokemon_train)
dim(pokemon_test)
```

```{r}
# v-fold cross validation w v = 5
pokemon_folds <- vfold_cv(pokemon_train, v = 5, strata = "type_1")
```

We straify the folds because there are a limited number of observations of each class and we want to make sure that none of the folds exclude a certain class of type_1.

### Exercise 4

```{r}
# generate recipe to predict type_1
pokemon_recipe <- recipe(type_1 ~ legendary + generation + sp_atk + attack + speed + defense + hp + sp_def, data = pokemon_train) %>% 
  # dummy vars for nominal predictors
  step_dummy(legendary, generation) %>% 
  # center
  step_center(all_predictors()) %>%
  # scale
  step_scale(all_predictors())
```

### Exercise 5

```{r}
# build model using multinom regression from glmnet engine, tuning penalty and mixture
pokemon_model <- 
  multinom_reg(penalty = tune(), mixture = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("glmnet")
# set up workflow
pokemon_workflow <- workflow() %>% 
  add_model(pokemon_model) %>% 
  add_recipe(pokemon_recipe)
```

We will be fitting 10 (penalty) x 10 (mixture) x 5 (folds) = 500 models

```{r}
# set up regular grid with mixture ranging from (0,1), penalty from (-5,5), and 10 levels of each
#pokemon_grid <- grid_regular(penalty(range = c(-5, 5)),  levels = 10)
pokemon_grid <- grid_regular(penalty(range = c(-5, 5)), mixture(range = c(0, 1)), levels = c(penalty = 10, mixture = 10))
```


### Exercise 6

```{r}
# fitting all 100 models with tune_grid()
pokemon_tuned_models <- tune_grid(
  pokemon_workflow,
  resamples = pokemon_folds, 
  grid = pokemon_grid
)
# autoplot to view results
autoplot(pokemon_tuned_models)
```

Smaller values for both `penalty` and `mixture` produce the best accuracies and ROC AUCs, however, for low `penalty` values, the mixture is largely irrelevant as all models perform similarly. As the penalty increases, the trend of smaller `mixture` values performing better shows up, and again for high `penalty` values all models perform poorly.

### Exercise 7

```{r}
# find best model according to roc_auc()
best_model <- select_best(pokemon_tuned_models, metric = "roc_auc")
# finalize workflow for this model
pokemon_final_wflow <- finalize_workflow(pokemon_workflow, best_model)
# fit final model to entire training set
pokemon_final_fit <- fit(pokemon_final_wflow, data = pokemon_train)
# evaluate performance on testing data

augment(pokemon_final_fit, new_data = pokemon_test) %>%
  accuracy(truth = type_1, estimate = .pred_class)
```

The best model only had a 34% accuracy when predicting the class of the testing data.

### Exercise 8

```{r}
# create class probabilities data frame
class_probs = augment(pokemon_final_fit, new_data = pokemon_test) 
# calculate ROC_AUC
roc_auc = class_probs %>% 
  roc_auc(truth = type_1, .pred_Bug:.pred_Water)

roc_auc
```

The overall ROC AUC on the pokemon testing set is .71

```{r}
# plot ROC curves for all types
roc_curve(class_probs, .pred_Bug:.pred_Water, truth = type_1) %>%
  autoplot()
```

```{r}
# build confusion matrix
cm = conf_mat(class_probs, estimate = .pred_class, truth = type_1)
# plot heatmap
autoplot(cm, type = "heatmap")
```

The model performed best when predicting Normal, Bug, Grass and Psychic pokemon types, and worst when predicting water (close to random chance). This could be due to number of observations of different classes or overlap in predictors. We see that water was very often mistaken for Normal, which could mean they were similar in characteristic and the model leaned towards predicting Normal.

## For 231 Students

### Exercise 9

In the 2020-2021 season, Stephen Curry, an NBA basketball player, made 337 out of 801 three point shot attempts (42.1%). Use bootstrap resampling on a sequence of 337 1’s (makes) and 464 0’s (misses). For each bootstrap sample, compute and save the sample mean (e.g. bootstrap FG% for the player). Use 1000 bootstrap samples to plot a histogram of those values. Compute the 99% bootstrap confidence interval for Stephen Curry’s “true” end-of-season
FG% using the quantile function in R. Print the endpoints of this interval.

```{r}
# build sequence of Steph Curries makes and misses
makes = matrix(data = 1, nrow = 337, ncol = 1) 
misses = matrix(data = 0, nrow = 464, ncol = 1)
shots = rbind(makes, misses) 
```

```{r}
# take 1000 samples and calculate means from sequence
means = matrix(data = 0, nrow = 1000, ncol = 1)
for (i in 1:1000) {
  means[i] = mean(sample(shots, replace = TRUE))
}
means = data.frame(means)
```

```{r}
# plot distribution of mean 3 pt %
ggplot(means, aes(x = means)) +
  geom_histogram(bins = 20) + 
  labs(x = "Mean 3-Pt %", y = "Count")
```

```{r}
# calculate 99% confidence interval
quantile(means$means, probs = c(.005, .995) )
```

The endpoint shooting percentages of the 99% confidence interval are [37.3%, 47.1%]